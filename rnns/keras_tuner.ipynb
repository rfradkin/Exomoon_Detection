{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MgTV4r-3hof9",
    "tags": []
   },
   "source": [
    "Formatting Guide:\n",
    "- Use yapf for PEP8 style guide (FormatCode())\n",
    "- Use blank lines sparingly, shows change in logic/focus\n",
    "- Variable names should be the first five letters of the description\n",
    "- Comment Code Accordingly\n",
    "- Anything with ### above and below needs to be updated\n",
    "\n",
    "Other Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import importlib\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import GPUtil\n",
    "\n",
    "# Project imports\n",
    "import ephesus\n",
    "import utils\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "# Specific GPUs\n",
    "desir_gpus = [2,3]\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices([gpus[i] for i in desir_gpus], 'GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "mirro_strat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oJZltv7qiPYr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent file: padde_cuts-34745-2850-6998.pkl\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent file in injec_curve\n",
    "datas = utils.retur_most_recen(f'{xom_data_path}padde_cuts/')\n",
    "# datas = 'padde_cuts-34745-2850-6998.pkl'\n",
    "print(f'Most recent file: {datas}')\n",
    "\n",
    "with open(f'{xom_data_path}padde_cuts/{datas}','rb') as f:\n",
    "    raw_x_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset composition setup\n",
    "DETEC_TYPE = 'plane_moon_cut_injec'\n",
    "NUMBE_RELEV = 8000\n",
    "NUMBE_IRREL = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00% of the dataset contains a full injection\n"
     ]
    }
   ],
   "source": [
    "# Separate full dataset into relevant and irrelevant components\n",
    "full_relev_index = []\n",
    "for i in range(len(raw_x_data)):\n",
    "    if raw_x_data[i, -1, 1][DETEC_TYPE]:\n",
    "        full_relev_index.append(i)\n",
    "        \n",
    "# Take a random sample of a relevant\n",
    "relev_index = random.sample(full_relev_index, NUMBE_RELEV)\n",
    "relev_curve = np.copy(raw_x_data[relev_index])\n",
    "# Take a random sample of a irrelevant\n",
    "irrel_curve = np.delete(raw_x_data, full_relev_index, axis=0)\n",
    "irrel_curve = irrel_curve[utils.retur_rando_sampl(NUMBE_IRREL, len(irrel_curve))]\n",
    "\n",
    "# Shuffle the order of the data\n",
    "rando_shuff_x_data = np.concatenate((relev_curve, irrel_curve), axis=0)\n",
    "np.random.shuffle(rando_shuff_x_data)\n",
    "\n",
    "# Normalize the data from 0 to 1\n",
    "norma_full_x_data = np.copy(rando_shuff_x_data)\n",
    "x_data = np.copy(rando_shuff_x_data[:, :-1, 1].astype(float))\n",
    "\n",
    "for i in range(len(x_data)):\n",
    "    chang_slots = np.where(x_data[i] != 0)[0]\n",
    "    x_data[i, chang_slots] = utils.norma_data(x_data[i, chang_slots])\n",
    "    norma_full_x_data[i, :-1, 1] = x_data[i]\n",
    "\n",
    "x_data = np.expand_dims(x_data, 2)\n",
    "\n",
    "# Create the corresponding y dataset\n",
    "y_data = np.zeros(len(norma_full_x_data))\n",
    "for i in range(len(norma_full_x_data)):\n",
    "    y_data[i] = norma_full_x_data[i, -1, 1][DETEC_TYPE]\n",
    "\n",
    "print(\n",
    "    f'{sum(y_data)/len(y_data):.2%} of the dataset contains a full injection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "\n",
    "stop = len(x_data) - len(y_data) % 100\n",
    "split = int(stop * 0.7)\n",
    "    \n",
    "x_train = np.array(x_data[:split])\n",
    "full_x_train = norma_full_x_data[:split]\n",
    "x_test = np.array(x_data[split:stop])\n",
    "full_x_test = norma_full_x_data[split:stop]\n",
    "y_train = y_data[:split]\n",
    "y_test = y_data[split:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-full batches (because they cause problems)\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# If no remainder, skip\n",
    "if x_train.shape[0] % BATCH_SIZE:\n",
    "    x_train = x_train[:-(x_train.shape[0] % BATCH_SIZE)]\n",
    "    full_x_train = full_x_train[:-(full_x_train.shape[0] % BATCH_SIZE)]\n",
    "    y_train = y_train[:-(y_train.shape[0] % BATCH_SIZE)]\n",
    "\n",
    "if x_test.shape[0] % BATCH_SIZE:\n",
    "    x_test = x_test[:-(x_test.shape[0] % BATCH_SIZE)]\n",
    "    full_x_test = full_x_test[:-(full_x_test.shape[0] % BATCH_SIZE)]\n",
    "    y_test = y_test[:-(y_test.shape[0] % BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline calculations for email updates\n",
    "# Baseline accuracy, precision, and recall are all the same\n",
    "basel_value = sum(y_test) / len(y_test) \n",
    "if basel_value < 0.5:\n",
    "    basel_value = 1 - basel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models\n",
    "NUMBE_OF_MODEL = 100\n",
    "# Number of executions per model\n",
    "EXECU_PER_MODEL = 1\n",
    "# Max number of epochs\n",
    "EPOCH = 250\n",
    "# Early stopping patience\n",
    "PATIE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Directory\n",
    "\n",
    "# New directory\n",
    "log_direc = f'{main_path}moon/keras_tuner/{utils.curre_time()}_kt'\n",
    "# Open previously used tuner\n",
    "# log_direc = f'{main_path}moon/keras_tuner/combi-padde_cuts-345235-30352-72662.pkl_1651418535'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'{main_path}tensorboard/{datas}_{int(time.time())}')\n",
    "early_stopp = EarlyStopping(monitor='val_accuracy', patience=PATIE)\n",
    "resto_valid_accur = utils.resto_best_valid_accur()\n",
    "email_train_progr = utils.email_train_progr()\n",
    "model_check_path = f'{log_direc}/redun_model/'\n",
    "try:\n",
    "    os.mkdir(f'{log_direc}')\n",
    "    os.mkdir(model_check_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "model_check = utils.custo_model_check(path=model_check_path)\n",
    "\n",
    "callb = [early_stopp, email_train_progr, resto_valid_accur, model_check]#, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuner_model(hyper):\n",
    "    \"\"\"RNN tuner model for use with keras tuner.\"\"\"\n",
    "\n",
    "    # Setup for model architecture\n",
    "    MAX_RNN_LAYER = 4\n",
    "    MAX_DENSE_LAYER = 4\n",
    "    dense_activ = [\"elu\", \"tanh\"]\n",
    "    metri = [\"accuracy\", utils.preci, utils.recal]\n",
    "    rnn_type = hyper.Choice(\"rnn_type\", [\"gru\", \"lstm\"])\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    # Add masking layer\n",
    "    model.add(layers.Masking(mask_value=0.0, input_shape=(1900, 1)))\n",
    "\n",
    "    if rnn_type == \"gru\" or initi:\n",
    "        with hyper.conditional_scope(\"rnn_type\", \"gru\"):\n",
    "            # Determine the number of GRU layers\n",
    "            try:\n",
    "                numbe_gru_layer = hyper.Int(f\"numbe_gru_layer\", 1, MAX_RNN_LAYER)\n",
    "                final_gru_units = hyper.Int(f\"final_gru_units\", 16, 256)\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "            if initi:\n",
    "                numbe_gru_layer = MAX_RNN_LAYER\n",
    "                final_gru_units = 0\n",
    "            for curre_gru_layer_numbe in range(1, numbe_gru_layer + 1):\n",
    "                with hyper.conditional_scope(\n",
    "                    \"numbe_gru_layer\",\n",
    "                    list(range(curre_gru_layer_numbe, numbe_gru_layer + 1)),\n",
    "                ):\n",
    "                    try:\n",
    "                        model.add(\n",
    "                            layers.GRU(\n",
    "                                hyper.Int(\n",
    "                                    f\"gru_{curre_gru_layer_numbe}_units\", 16, 256\n",
    "                                ),\n",
    "                                activation=\"tanh\",\n",
    "                                return_sequences=True,\n",
    "                            )\n",
    "                        )\n",
    "                    except (TypeError, KeyError):\n",
    "                        pass\n",
    "\n",
    "    if rnn_type == \"lstm\" or initi:\n",
    "        with hyper.conditional_scope(\"rnn_type\", \"lstm\"):\n",
    "            # Determine the number of lstm layers\n",
    "            try:\n",
    "                numbe_lstm_layer = hyper.Int(f\"numbe_lstm_layer\", 1, MAX_RNN_LAYER)\n",
    "                final_lstm_units = hyper.Int(f\"final_lstm_units\", 16, 256)\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "            if initi:\n",
    "                numbe_lstm_layer = MAX_RNN_LAYER\n",
    "                final_lstm_units = 0\n",
    "            for curre_lstm_layer_numbe in range(1, numbe_lstm_layer + 1):\n",
    "                with hyper.conditional_scope(\n",
    "                    \"numbe_lstm_layer\",\n",
    "                    list(range(curre_lstm_layer_numbe, numbe_lstm_layer + 1)),\n",
    "                ):\n",
    "                    try:\n",
    "                        model.add(\n",
    "                            layers.LSTM(\n",
    "                                hyper.Int(\n",
    "                                    f\"lstm_{curre_lstm_layer_numbe}_units\", 16, 256\n",
    "                                ),\n",
    "                                activation=\"tanh\",\n",
    "                                return_sequences=True,\n",
    "                            )\n",
    "                        )\n",
    "                    except (TypeError, KeyError) as e:\n",
    "                        pass\n",
    "\n",
    "    if rnn_type == \"gru\":\n",
    "        model.add(layers.GRU(final_gru_units, activation=\"tanh\"))\n",
    "    elif rnn_type == \"lstm\":\n",
    "        model.add(layers.LSTM(final_lstm_units, activation=\"tanh\"))\n",
    "\n",
    "    # Determine the number of rnn and dense layers\n",
    "    numbe_dense_layer = hyper.Int(f\"numbe_dense_layer\", 1, MAX_DENSE_LAYER)\n",
    "    if initi:\n",
    "        numbe_dense_layer = MAX_DENSE_LAYER\n",
    "\n",
    "    # Add the dense and dropout layers\n",
    "    for curre_dense_layer_numbe in range(1, numbe_dense_layer + 1):\n",
    "        with hyper.conditional_scope(\n",
    "            \"numbe_dense_layer\",\n",
    "            list(range(curre_dense_layer_numbe, numbe_dense_layer + 1)),\n",
    "        ):\n",
    "            try:\n",
    "                model.add(\n",
    "                    layers.Dense(\n",
    "                        hyper.Int(f\"dense_{curre_dense_layer_numbe}_units\", 16, 256),\n",
    "                        activation=hyper.Choice(\n",
    "                            f\"dense_{curre_dense_layer_numbe}_activ\", dense_activ\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "                model.add(\n",
    "                    layers.Dropout(\n",
    "                        hyper.Float(\n",
    "                            f\"dense_{curre_dense_layer_numbe}_dropo\", 0, 1 - 1e-6\n",
    "                        )\n",
    "                    )\n",
    "                )  # Dropout must be between [0, 1)\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "\n",
    "    # Add the sigmoid activation for binary classification\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Setup the learning and decay rate\n",
    "    learn_rate = hyper.Float(\"learn_rate\", 1e-6, 1e-2)\n",
    "    decay_rate = hyper.Float(\"decay_rate\", 1e-6, 1e-2)\n",
    "\n",
    "    # Create the optimizer (always Nadam)\n",
    "    optim = tf.keras.optimizers.Nadam(learning_rate=learn_rate, decay=decay_rate)\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"BinaryCrossentropy\", optimizer=optim, metrics=metri)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "### all the try except typeerror statemetns are added cause initial values are none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.tuner_messa_backg_infor(setup=True, total_trial_numbe=(NUMBE_OF_MODEL*EXECU_PER_MODEL), total_epoch_numbe=EPOCH,\n",
    "                              basel_accur=basel_value, basel_preci=basel_value, basel_recal=basel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initi = True\n",
    "tuner = kt.BayesianOptimization(hypermodel=tuner_model,\n",
    "                                objective='val_accuracy',\n",
    "                                max_trials=NUMBE_OF_MODEL,\n",
    "                                executions_per_trial=EXECU_PER_MODEL,\n",
    "                                distribution_strategy=mirro_strat,\n",
    "                                overwrite=False,\n",
    "                                directory=log_direc,\n",
    "                                project_name='exomo_rnn')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 02m 58s]\n",
      "val_accuracy: 0.5099999904632568\n",
      "\n",
      "Best val_accuracy So Far: 0.5099999904632568\n",
      "Total elapsed time: 00h 13m 23s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5893d06da14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# while infor[\"curre_trial_numbe\"][0] != (NUMBE_OF_MODEL * EXECU_PER_MODEL):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     tuner.search(x_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m                  \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOPPED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;31m# Oracle triggered exit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/oracle.py\u001b[0m in \u001b[0;36mcreate_trial\u001b[0;34m(self, tuner_id)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"values\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/tuners/bayesian.py\u001b[0m in \u001b[0;36mpopulate_space\u001b[0;34m(self, trial_id)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"array must not contain infs or NaNs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/tuners/bayesian.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# l_matrix * l_matrix^T == kernel_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_l_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_l_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/tuners/bayesian.py\u001b[0m in \u001b[0;36mcho_solve\u001b[0;34m(l_matrix, b)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Ax=b LL^T=A => Ly=b L^Tx=y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msolve_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/tuners/bayesian.py\u001b[0m in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, lower)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriangular_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"array must not contain infs or NaNs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36mmatrix_triangular_solve\u001b[0;34m(matrix, rhs, lower, adjoint, name)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \"\"\"\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'triangular_solve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     return gen_linalg_ops.matrix_triangular_solve(\n\u001b[0m\u001b[1;32m    141\u001b[0m         matrix, rhs, lower=lower, adjoint=adjoint)\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36mmatrix_triangular_solve\u001b[0;34m(matrix, rhs, lower, adjoint, name)\u001b[0m\n\u001b[1;32m   1875\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatrixTriangularSolve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         tld.op_callbacks, matrix, rhs, \"lower\", lower, \"adjoint\", adjoint)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initi = False\n",
    "# infor = pd.read_csv(f'{main_path}rnns/tuner_backg_infor.csv')\n",
    "# while infor[\"curre_trial_numbe\"][0] != (NUMBE_OF_MODEL * EXECU_PER_MODEL):\n",
    "try:\n",
    "    tuner.search(x_train,\n",
    "                 y_train,\n",
    "                 verbose=2,\n",
    "                 epochs=EPOCH,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 callbacks=callb,\n",
    "                 validation_data=(x_test, y_test))\n",
    "except Exception as excep:\n",
    "    utils.send_task_comple_email('Trial Error', f'{type(excep).__name__}: {str(excep)}')\n",
    "    raise excep\n",
    "        # infor['curre_trial_numbe'] += 1\n",
    "        # infor.to_csv(f'{main_path}rnns/tuner_backg_infor.csv', index=False)\n",
    "    \n",
    "    # infor = pd.read_csv(f'{main_path}rnns/tuner_backg_infor.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "3bpE0Vg96nYF"
   },
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.send_task_comple_email('KT')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trial = tuner.oracle.get_trial('a8ae2be72c5215829e283799e27a9066')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = tuner.hypermodel.build(trial.hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "for model_num in range(len(model)):\n",
    "    model_path = f'{xom_data_path}plane_moon_model/{datas}-{model_num}-{int(time.time())}.h5'\n",
    "    model[model_num].save(model_path)\n",
    "    print(f'Best Model Path: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = 0\n",
    "stop = None\n",
    "\n",
    "x_full_predi_data = full_x_test[start:stop]\n",
    "x_predi_data = x_test[start:stop]\n",
    "y_predi_data = y_test[start:stop]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_file = f'padde_cuts-1_1-parti-1636835330.0437317.pkl-75.238.h5'\n",
    "model = tf.keras.models.load_model(f'{xom_data_path}plane_moon_model/{model_file}');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "predi = model[0].predict(x_predi_data).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importlib.reload(utils);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.log_predi_infor(x_full_predi_data, predi, f'{main_path}predi_logs/', model_file, datas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cutof = 0.98"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_preci_recal(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_roc(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_tpr_fpr(x_full_predi_data, predi, .5, 'moon_radiu', 30, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_confu_matri(x_full_predi_data, predi, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [130, 230], 'true',\n",
    "                       ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forma = \\\n",
    "'''\n",
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [30,130], 'true', ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])\n",
    "'''\n",
    "forma_done = FormatCode(forma, style_config='PEP8')\n",
    "print(forma_done[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "xom",
   "language": "python",
   "name": "xom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
