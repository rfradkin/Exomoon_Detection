{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MgTV4r-3hof9",
    "tags": []
   },
   "source": [
    "Formatting Guide:\n",
    "- Use yapf for PEP8 style guide (FormatCode())\n",
    "- Use blank lines sparingly, shows change in logic/focus\n",
    "- Variable names should be the first five letters of the description\n",
    "- Comment Code Accordingly\n",
    "- Anything with ### above and below needs to be updated\n",
    "\n",
    "Other Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import importlib\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import GPUtil\n",
    "\n",
    "# Project imports\n",
    "import ephesus\n",
    "import utils\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "# Specific GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[2:4], 'GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "mirro_strat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oJZltv7qiPYr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent file: combi-padde_cuts-345235-30352-72662.pkl\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent file in injec_curve\n",
    "datas = utils.retur_most_recen(f'{xom_data_path}padde_cuts/')\n",
    "# datas = 'padde_cuts-34745-2850-6998.pkl'\n",
    "print(f'Most recent file: {datas}')\n",
    "\n",
    "with open(f'{xom_data_path}padde_cuts/{datas}','rb') as f:\n",
    "    raw_x_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset composition setup\n",
    "DETEC_TYPE = 'plane_moon_cut_injec'\n",
    "NUMBE_RELEV = 22000\n",
    "NUMBE_IRREL = 28000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00% of the dataset contains a full injection\n"
     ]
    }
   ],
   "source": [
    "# Separate full dataset into relevant and irrelevant components\n",
    "full_relev_index = []\n",
    "for i in range(len(raw_x_data)):\n",
    "    if raw_x_data[i, -1, 1][DETEC_TYPE]:\n",
    "        full_relev_index.append(i)\n",
    "        \n",
    "# Take a random sample of a relevant\n",
    "relev_index = random.sample(full_relev_index, NUMBE_RELEV)\n",
    "relev_curve = np.copy(raw_x_data[relev_index])\n",
    "# Take a random sample of a irrelevant\n",
    "irrel_curve = np.delete(raw_x_data, full_relev_index, axis=0)\n",
    "irrel_curve = irrel_curve[utils.retur_rando_sampl(NUMBE_IRREL, len(irrel_curve))]\n",
    "\n",
    "# Shuffle the order of the data\n",
    "rando_shuff_x_data = np.concatenate((relev_curve, irrel_curve), axis=0)\n",
    "np.random.shuffle(rando_shuff_x_data)\n",
    "\n",
    "# Normalize the data from 0 to 1\n",
    "norma_full_x_data = np.copy(rando_shuff_x_data)\n",
    "x_data = np.copy(rando_shuff_x_data[:, :-1, 1].astype(float))\n",
    "\n",
    "for i in range(len(x_data)):\n",
    "    chang_slots = np.where(x_data[i] != 0)[0]\n",
    "    x_data[i, chang_slots] = utils.norma_data(x_data[i, chang_slots])\n",
    "    norma_full_x_data[i, :-1, 1] = x_data[i]\n",
    "\n",
    "x_data = np.expand_dims(x_data, 2)\n",
    "\n",
    "# Create the corresponding y dataset\n",
    "y_data = np.zeros(len(norma_full_x_data))\n",
    "for i in range(len(norma_full_x_data)):\n",
    "    y_data[i] = norma_full_x_data[i, -1, 1][DETEC_TYPE]\n",
    "\n",
    "print(\n",
    "    f'{sum(y_data)/len(y_data):.2%} of the dataset contains a full injection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "\n",
    "stop = len(x_data) - len(y_data) % 100\n",
    "split = int(stop * 0.7)\n",
    "    \n",
    "x_train = np.array(x_data[:split])\n",
    "full_x_train = norma_full_x_data[:split]\n",
    "x_test = np.array(x_data[split:stop])\n",
    "full_x_test = norma_full_x_data[split:stop]\n",
    "y_train = y_data[:split]\n",
    "y_test = y_data[split:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-full batches (because they cause problems)\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# If no remainder, skip\n",
    "if x_train.shape[0] % BATCH_SIZE:\n",
    "    x_train = x_train[:-(x_train.shape[0] % BATCH_SIZE)]\n",
    "    full_x_train = full_x_train[:-(full_x_train.shape[0] % BATCH_SIZE)]\n",
    "    y_train = y_train[:-(y_train.shape[0] % BATCH_SIZE)]\n",
    "\n",
    "if x_test.shape[0] % BATCH_SIZE:\n",
    "    x_test = x_test[:-(x_test.shape[0] % BATCH_SIZE)]\n",
    "    full_x_test = full_x_test[:-(full_x_test.shape[0] % BATCH_SIZE)]\n",
    "    y_test = y_test[:-(y_test.shape[0] % BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline calculations for email updates\n",
    "# Baseline accuracy, precision, and recall are all the same\n",
    "basel_value = sum(y_test) / len(y_test) \n",
    "if basel_value < 0.5:\n",
    "    basel_value = 1 - basel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models\n",
    "NUMBE_OF_MODEL = 80\n",
    "# Number of executions per model\n",
    "EXECU_PER_MODEL = 1\n",
    "# Max number of epochs\n",
    "EPOCH = 25\n",
    "# Early stopping patience\n",
    "PATIE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'{main_path}tensorboard/{datas}_{int(time.time())}')\n",
    "early_stopp = EarlyStopping(monitor='val_accuracy', patience=PATIE)\n",
    "resto_valid_accur = utils.resto_best_valid_accur()\n",
    "email_train_progr = utils.email_train_progr()\n",
    "\n",
    "callb = [resto_valid_accur, early_stopp, email_train_progr]#, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_direc = f'{main_path}keras_tuner/{datas}_{int(time.time())}'\n",
    "def tuner_model(hyper):\n",
    "    '''RNN tuner model for use with keras tuner.'''\n",
    "\n",
    "    # Setup for model architecture\n",
    "    MAX_RNN_LAYER = 6\n",
    "    MAX_DENSE_LAYER = 6\n",
    "    dense_activ = ['elu', 'tanh']\n",
    "    metri = ['accuracy', utils.preci, utils.recal]\n",
    "    rnn_type = hyper.Choice('rnn_type', ['lstm', 'gru'])\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    # Add masking layer\n",
    "    model.add(layers.Masking(mask_value=0.0,input_shape=(1900, 1)))\n",
    "    \n",
    "    if rnn_type == 'gru'  or initi:  \n",
    "        with hyper.conditional_scope('rnn_type', 'gru'):\n",
    "            # Determine the number of GRU layers\n",
    "            try:\n",
    "                numbe_gru_layer = hyper.Int(f'numbe_gru_layer', 1, MAX_RNN_LAYER)\n",
    "                final_gru_units = hyper.Int(f'final_gru_units', 32, 256)\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "            if initi:\n",
    "                numbe_gru_layer = MAX_RNN_LAYER\n",
    "                final_gru_units = 0\n",
    "            for curre_gru_layer_numbe in range(1, numbe_gru_layer):\n",
    "                with hyper.conditional_scope('numbe_gru_layer', list(range(curre_gru_layer_numbe, numbe_gru_layer + 1))):\n",
    "                    try:\n",
    "                        model.add(layers.GRU(hyper.Int(f'gru_{curre_gru_layer_numbe}_units', 16, 256), \n",
    "                                               activation='tanh', return_sequences=True))\n",
    "                    except (TypeError, KeyError):\n",
    "                        pass               \n",
    "         \n",
    "    if rnn_type == 'lstm' or initi:  \n",
    "        with hyper.conditional_scope('rnn_type', 'lstm'):\n",
    "            # Determine the number of lstm layers\n",
    "            try:\n",
    "                numbe_lstm_layer = hyper.Int(f'numbe_lstm_layer', 1, MAX_RNN_LAYER)\n",
    "                final_lstm_units = hyper.Int(f'final_lstm_units', 32, 256)\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "            if initi:\n",
    "                numbe_lstm_layer = MAX_RNN_LAYER\n",
    "                final_lstm_units = 0\n",
    "            for curre_lstm_layer_numbe in range(1, numbe_lstm_layer):\n",
    "                with hyper.conditional_scope('numbe_lstm_layer', list(range(curre_lstm_layer_numbe, numbe_lstm_layer + 1))):\n",
    "                    try:\n",
    "                        model.add(layers.LSTM(hyper.Int(f'lstm_{curre_lstm_layer_numbe}_units',16, 256), activation='tanh', return_sequences=True))\n",
    "                    except (TypeError, KeyError) as e:\n",
    "                        pass\n",
    "                        \n",
    "    if rnn_type == 'gru':\n",
    "        model.add(layers.GRU(final_gru_units, activation='tanh'))\n",
    "    elif rnn_type == 'lstm':\n",
    "        model.add(layers.LSTM(final_lstm_units, activation='tanh')) \n",
    "        \n",
    "    # Determine the number of rnn and dense layers\n",
    "    numbe_dense_layer = hyper.Int(f'numbe_dense_layer', 1, MAX_DENSE_LAYER)\n",
    "    if initi:\n",
    "        numbe_dense_layer = MAX_DENSE_LAYER\n",
    "        \n",
    "    # Add the dense and dropout layers\n",
    "    for curre_dense_layer_numbe in range(1, numbe_dense_layer):\n",
    "        with hyper.conditional_scope('numbe_dense_layer', list(range(curre_dense_layer_numbe, numbe_dense_layer + 1))):\n",
    "            try:\n",
    "                model.add(layers.Dense(hyper.Int(f'dense_{curre_dense_layer_numbe}_units', 16, 256), \n",
    "                                       activation=hyper.Choice(f'dense_{curre_dense_layer_numbe}_activ', dense_activ)))\n",
    "                model.add(layers.Dropout(hyper.Float(f'dense_{curre_dense_layer_numbe}_dropo', 0, 1)))\n",
    "            except (TypeError, KeyError):\n",
    "                pass\n",
    "        \n",
    "    # Add the sigmoid activation for binary classification\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    # Setup the learning and decay rate\n",
    "    learn_rate = hyper.Float('learn_rate', 1e-6, 1e-2)\n",
    "    decay_rate = hyper.Float('decay_rate', 1e-6, 1e-2)\n",
    "\n",
    "    # Create the optimizer (always Nadam)\n",
    "    optim = tf.keras.optimizers.Nadam(learning_rate=learn_rate,\n",
    "                                    decay=decay_rate)\n",
    "    # Compile the model\n",
    "    model.compile(loss='BinaryCrossentropy',\n",
    "                  optimizer=optim,\n",
    "                  metrics=metri)\n",
    "\n",
    "    return model\n",
    "\n",
    "### all the try except typeerror statemetns are added cause initial values are none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.tuner_messa_backg_infor(setup=True, total_trial_numbe=(NUMBE_OF_MODEL*EXECU_PER_MODEL), total_epoch_numbe=EPOCH,\n",
    "                              basel_accur=basel_value, basel_preci=basel_value, basel_recal=basel_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "initi = True\n",
    "tuner = kt.BayesianOptimization(hypermodel=tuner_model,\n",
    "                                objective='val_accuracy',\n",
    "                                max_trials=NUMBE_OF_MODEL,\n",
    "                                executions_per_trial=EXECU_PER_MODEL,\n",
    "                                distribution_strategy=mirro_strat,\n",
    "                                directory=log_direc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 05s]\n",
      "val_accuracy: 0.5400000214576721\n",
      "\n",
      "Best val_accuracy So Far: 0.5400000214576721\n",
      "Total elapsed time: 00h 04m 05s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "rnn_type          |gru               |gru               \n",
      "numbe_gru_layer   |2                 |6                 \n",
      "final_gru_units   |159               |87                \n",
      "gru_1_units       |186               |20                \n",
      "gru_2_units       |111               |189               \n",
      "numbe_dense_layer |3                 |5                 \n",
      "dense_1_units     |157               |201               \n",
      "dense_1_activ     |elu               |elu               \n",
      "dense_1_dropo     |0.74111           |0.91512           \n",
      "dense_2_units     |188               |242               \n",
      "dense_2_activ     |tanh              |elu               \n",
      "dense_3_units     |201               |103               \n",
      "dense_3_activ     |elu               |elu               \n",
      "learn_rate        |0.001809          |0.0089584         \n",
      "decay_rate        |0.0057697         |0.0090851         \n",
      "dense_2_dropo     |0.71666           |0                 \n",
      "dense_3_dropo     |0.73123           |0                 \n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fafc045eae9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miniti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     tuner.search(x_train,\n\u001b[0m\u001b[1;32m      4\u001b[0m                  \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xom/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initi = False\n",
    "try:\n",
    "    tuner.search(x_train,\n",
    "                 y_train,\n",
    "                 verbose=2,\n",
    "                 epochs=EPOCH,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 callbacks=callb,\n",
    "                 validation_data=(x_test, y_test))\n",
    "except Exception as excep:\n",
    "    utils.send_task_comple_email('Trial Error', str(excep))\n",
    "    raise excep"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "3bpE0Vg96nYF"
   },
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.send_task_comple_email('KT')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "for model_num in range(len(model)):\n",
    "    model_path = f'{xom_data_path}plane_moon_model/{datas}-{model_num}-{int(time.time())}.h5'\n",
    "    model[model_num].save(model_path)\n",
    "    print(f'Best Model Path: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = 0\n",
    "stop = None\n",
    "\n",
    "x_full_predi_data = full_x_test[start:stop]\n",
    "x_predi_data = x_test[start:stop]\n",
    "y_predi_data = y_test[start:stop]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_file = f'padde_cuts-1_1-parti-1636835330.0437317.pkl-75.238.h5'\n",
    "model = tf.keras.models.load_model(f'{xom_data_path}plane_moon_model/{model_file}');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "predi = model[0].predict(x_predi_data).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importlib.reload(utils);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.log_predi_infor(x_full_predi_data, predi, f'{main_path}predi_logs/', model_file, datas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cutof = 0.98"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_preci_recal(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_roc(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_tpr_fpr(x_full_predi_data, predi, .5, 'moon_radiu', 30, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_confu_matri(x_full_predi_data, predi, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [130, 230], 'true',\n",
    "                       ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forma = \\\n",
    "'''\n",
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [30,130], 'true', ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])\n",
    "'''\n",
    "forma_done = FormatCode(forma, style_config='PEP8')\n",
    "print(forma_done[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "xom",
   "language": "python",
   "name": "xom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
