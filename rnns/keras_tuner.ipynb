{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MgTV4r-3hof9",
    "tags": []
   },
   "source": [
    "Formatting Guide:\n",
    "- Use yapf for PEP8 style guide (FormatCode())\n",
    "- Use blank lines sparingly, shows change in logic/focus\n",
    "- Variable names should be the first five letters of the description\n",
    "- Comment Code Accordingly\n",
    "- Anything with ### above and below needs to be updated\n",
    "\n",
    "Other Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import importlib\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import GPUtil\n",
    "\n",
    "# Project imports\n",
    "import ephesus\n",
    "import utils\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Only CPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_228332/3324549603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Specific GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# gpus = tf.config.experimental.list_physical_devices('GPU')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmirror_strat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirroredStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Specific GPUs\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[1:4], 'GPU')\n",
    "mirror_strat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "# from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "# All GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 22:01:09.336247: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-19 22:01:09.360181: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55a16dc29630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-19 22:01:09.360212: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-19 22:01:09.950533: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55a1690c8120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-19 22:01:09.950574: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:01:09.950584: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:01:09.950590: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:01:09.950597: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:01:12.065052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44388 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2022-03-19 22:01:12.067593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46464 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2022-03-19 22:01:12.070107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46464 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:86:00.0, compute capability: 8.6\n",
      "2022-03-19 22:01:12.072560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46464 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "mirror_strat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 22:06:23.245828: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-19 22:06:23.282356: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55efd1a2b6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-19 22:06:23.282395: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-19 22:06:23.870981: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55efd11b1b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-19 22:06:23.871045: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:06:23.871065: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:06:23.871080: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:06:23.871094: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2022-03-19 22:06:26.014317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44388 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2022-03-19 22:06:26.020633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46464 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2022-03-19 22:06:26.027037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 46464 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:86:00.0, compute capability: 8.6\n",
      "2022-03-19 22:06:26.032945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46464 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# All GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print('here')\n",
    "    try:\n",
    "        print('here')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "mirror_strat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###      DOUBLE CHECK      ###\n",
    "detec_type = 'plane_moon_cut_injec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oJZltv7qiPYr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent file: padde_cuts-34925-1370-8598.pkl\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent file in injec_curve\n",
    "datas = utils.retur_most_recen(f'{xom_data_path}padde_cuts/')\n",
    "# datas = 'padde_cuts-89885-not_detre-separ_moon_signa-1644394304.pkl'\n",
    "print(f'Most recent file: {datas}')\n",
    "\n",
    "with open(f'{xom_data_path}padde_cuts/{datas}','rb') as f:\n",
    "    raw_x_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.15% of the dataset contains a full injection\n"
     ]
    }
   ],
   "source": [
    "numbe_sampl = -1\n",
    "\n",
    "# Create a shuffled sample of the data\n",
    "rando_shuff_x_data = raw_x_data[utils.retur_rando_sampl(\n",
    "    numbe_sampl, len(raw_x_data))]\n",
    "np.random.shuffle(rando_shuff_x_data)\n",
    "\n",
    "# Normalize the data from 0 to 1\n",
    "norma_full_x_data = np.copy(rando_shuff_x_data)\n",
    "x_data = np.copy(rando_shuff_x_data[:, :-1, 1].astype(float))\n",
    "\n",
    "for i in range(len(x_data)):\n",
    "    chang_slots = np.where(x_data[i] != 0)[0]\n",
    "    x_data[i, chang_slots] = utils.norma_data(x_data[i, chang_slots])\n",
    "    norma_full_x_data[i, :-1, 1] = x_data[i]\n",
    "\n",
    "x_data = np.expand_dims(x_data, 2)\n",
    "\n",
    "# Create the corresponding y dataset\n",
    "y_data = np.zeros(len(norma_full_x_data))\n",
    "for i in range(len(norma_full_x_data)):\n",
    "    y_data[i] = norma_full_x_data[i, -1, 1][detec_type]\n",
    "\n",
    "print(\n",
    "    f'{sum(y_data)/len(y_data):.2%} of the dataset contains a full injection')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "\n",
    "stop = len(x_data) - len(y_data) % 100\n",
    "split = int(stop * 0.7)\n",
    "    \n",
    "x_train_np = np.array(x_data[:split])\n",
    "full_x_train = norma_full_x_data[:split]\n",
    "x_test_np = np.array(x_data[split:stop])\n",
    "full_x_test = norma_full_x_data[split:stop]\n",
    "y_train_np = y_data[:split]\n",
    "y_test_np = y_data[split:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the data\n",
    "masking = layers.Masking(mask_value=0., input_shape = (1900, 1))\n",
    "\n",
    "x_train_unmas = tf.convert_to_tensor(x_train_np)\n",
    "x_test_unmas = tf.convert_to_tensor(x_test_np)\n",
    "y_train = tf.convert_to_tensor(y_train_np)\n",
    "y_test = tf.convert_to_tensor(y_test_np)\n",
    "x_train = masking(x_train_unmas)\n",
    "x_test = masking(x_test_unmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'{main_path}tensorboard/{datas}_{int(time.time())}')\n",
    "early_stopp = EarlyStopping(monitor='val_accuracy', patience=6)\n",
    "resto_valid_accur = utils.resto_best_valid_accur()\n",
    "email_train_progr = utils.email_train_progr()\n",
    "\n",
    "callb = [resto_valid_accur, early_stopp, email_train_progr]#, tensorboard]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_direc = f'{main_path}keras_tuner/{datas}_{int(time.time())}'\n",
    "\n",
    "def tuner_model(hyper):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    lstm_gru = hyper.Choice('LSTM/GRU', ['LSTM', 'GRU'])\n",
    "    if lstm_gru == 'LSTM':\n",
    "        numbe_lstm = hyper.Int('numbe lstm layers', 1, 3)\n",
    "        if numbe_lstm == 1 and not initi:\n",
    "            model.add(\n",
    "                layers.LSTM(hyper.Int('lstm 1 units', 32, 256, 16),\n",
    "                            input_shape=(1900, 1),\n",
    "                            activation='tanh'))\n",
    "        else:\n",
    "            model.add(\n",
    "                layers.LSTM(hyper.Int('lstm 1 units', 32, 256, 16),\n",
    "                            input_shape=(1900, 1),\n",
    "                            activation='tanh',\n",
    "                            return_sequences=True))\n",
    "        if numbe_lstm == 2:\n",
    "            model.add(\n",
    "                layers.LSTM(hyper.Int('lstm 2 units', 32, 256, 16),\n",
    "                            activation='tanh'))\n",
    "        elif numbe_lstm == 3 or initi:\n",
    "            model.add(\n",
    "                layers.LSTM(hyper.Int('lstm 2 units', 32, 256, 16),\n",
    "                            activation='tanh',\n",
    "                            return_sequences=True))\n",
    "            if initi:\n",
    "                model.add(\n",
    "                    layers.LSTM(hyper.Int('lstm 3 units', 32, 256, 16),\n",
    "                                activation='tanh',\n",
    "                                return_sequences=True))\n",
    "            else:\n",
    "                model.add(\n",
    "                    layers.LSTM(hyper.Int('lstm 3 units', 32, 256, 16),\n",
    "                                activation='tanh'))\n",
    "\n",
    "    if lstm_gru == 'GRU' or initi:\n",
    "        numbe_gru = hyper.Int('numbe gru layers', 1, 3)\n",
    "        if numbe_gru == 1 and not initi:\n",
    "            model.add(\n",
    "                layers.GRU(hyper.Int('gru 1 units', 32, 256, 16),\n",
    "                           input_shape=(1900, 1),\n",
    "                           activation='tanh'))\n",
    "        else:\n",
    "            model.add(\n",
    "                layers.GRU(hyper.Int('gru 1 units', 32, 256, 16),\n",
    "                           input_shape=(1900, 1),\n",
    "                           activation='tanh',\n",
    "                           return_sequences=True))\n",
    "        if numbe_gru == 2:\n",
    "            model.add(\n",
    "                layers.GRU(hyper.Int('gru 2 units', 32, 256, 16),\n",
    "                           activation='tanh'))\n",
    "        elif numbe_gru == 3 or initi:\n",
    "            model.add(\n",
    "                layers.GRU(hyper.Int('gru 2 units', 32, 256, 16),\n",
    "                           activation='tanh',\n",
    "                           return_sequences=True))\n",
    "            model.add(\n",
    "                layers.GRU(hyper.Int('gru 3 units', 32, 256, 16),\n",
    "                           activation='tanh'))\n",
    "\n",
    "    numbe_dense = hyper.Int('numbe dense layers', 2, 6)\n",
    "    elu_tanh_PReLU1 = hyper.Choice('elu/tanh/PreLU 1',\n",
    "                                   ['elu', 'tanh', 'PReLU'])\n",
    "    model.add(\n",
    "        layers.Dense(hyper.Int(f'dense 1', 16, 256, 16),\n",
    "                     activation=elu_tanh_PReLU1))\n",
    "    model.add(layers.Dropout(hyper.Float('float dropout 1', 0, .9)))\n",
    "\n",
    "    if numbe_dense >= 2 or initi:\n",
    "        elu_tanh_PReLU2 = hyper.Choice('elu/tanh/PreLU 2',\n",
    "                                       ['elu', 'tanh', 'PReLU'])\n",
    "        model.add(\n",
    "            layers.Dense(hyper.Int(f'dense 2', 16, 256, 16),\n",
    "                         activation=elu_tanh_PReLU2))\n",
    "        model.add(layers.Dropout(hyper.Float('float dropout 2', 0, .9)))\n",
    "    if numbe_dense >= 3 or initi:\n",
    "        elu_tanh_PReLU3 = hyper.Choice('elu/tanh/PreLU 3',\n",
    "                                       ['elu', 'tanh', 'PReLU'])\n",
    "        model.add(\n",
    "            layers.Dense(hyper.Int(f'dense 3', 16, 256, 16),\n",
    "                         activation=elu_tanh_PReLU3))\n",
    "        model.add(layers.Dropout(hyper.Float('float dropout 3', 0, .9)))\n",
    "    if numbe_dense >= 4 or initi:\n",
    "        elu_tanh_PReLU4 = hyper.Choice('elu/tanh/PreLU 4',\n",
    "                                       ['elu', 'tanh', 'PReLU'])\n",
    "        model.add(\n",
    "            layers.Dense(hyper.Int(f'dense 4', 16, 256, 16),\n",
    "                         activation=elu_tanh_PReLU4))\n",
    "        model.add(layers.Dropout(hyper.Float('float dropout 4', 0, .9)))\n",
    "    if numbe_dense >= 5 or initi:\n",
    "        elu_tanh_PReLU5 = hyper.Choice('elu/tanh/PreLU 5',\n",
    "                                       ['elu', 'tanh', 'PReLU'])\n",
    "        model.add(\n",
    "            layers.Dense(hyper.Int(f'dense 5', 16, 256, 16),\n",
    "                         activation=elu_tanh_PReLU5))\n",
    "        model.add(layers.Dropout(hyper.Float('float dropout 5', 0, .9)))\n",
    "    if numbe_dense >= 6 or initi:\n",
    "        elu_tanh_PReLU6 = hyper.Choice('elu/tanh/PreLU 6',\n",
    "                                       ['elu', 'tanh', 'PReLU'])\n",
    "        model.add(\n",
    "            layers.Dense(hyper.Int(f'dense 6', 16, 256, 16),\n",
    "                         activation=elu_tanh_PReLU6))\n",
    "        model.add(layers.Dropout(hyper.Float('float dropout 6', 0, .9)))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    clipnorm_val = hyper.Float('clipnorm value', 0.1, 0.9)\n",
    "    lr = hyper.Float('learning rate', 1e-6, 1e-2)\n",
    "    dr = hyper.Float('decay rate', 1e-6, 1e-2)\n",
    "\n",
    "    opt = tf.keras.optimizers.Nadam(learning_rate=lr,\n",
    "                                    decay=dr,\n",
    "                                    clipnorm=clipnorm_val)\n",
    "\n",
    "    model.compile(loss='BinaryCrossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "iN--Ad0p6Z7p"
   },
   "source": [
    "initi = True\n",
    "tuner = kt.BayesianOptimization(hypermodel=tuner_model,\n",
    "                                objective='val_accuracy',\n",
    "                                max_trials=50,\n",
    "                                executions_per_trial=1,\n",
    "                                distribution_strategy=mirror_strat,\n",
    "                                directory=log_direc,\n",
    "                                project_name='Exomoon RNN')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "3bpE0Vg96nYF"
   },
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initi = False\n",
    "tuner.search(x_train,\n",
    "             y_train,\n",
    "             verbose=2,\n",
    "             epochs=50,\n",
    "             batch_size=64,\n",
    "             callbacks=callb,\n",
    "             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.send_task_comple_email('KT')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "model_path = f'{xom_data_path}plane_moon_model/{datas}-{model_num}-{int(time.time())}.h5'\n",
    "model[model_num].save(model_path)\n",
    "print(f'Best Model Path: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Path: /data/scratch/data/moon/plane_moon_model/padde_cuts-not_detre--1642315002.pkl-0-1642476005.h5\n"
     ]
    }
   ],
   "source": [
    "model_num = 0\n",
    "for model_num in range(len(model)):\n",
    "    model_path = f'{xom_data_path}plane_moon_model/{datas}-{model_num}-{int(time.time())}.h5'\n",
    "    model[model_num].save(model_path)\n",
    "    print(f'Best Model Path: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = 0\n",
    "stop = None\n",
    "\n",
    "x_full_predi_data = full_x_test[start:stop]\n",
    "x_predi_data = x_test[start:stop]\n",
    "y_predi_data = y_test_np[start:stop]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_file = f'padde_cuts-1_1-parti-1636835330.0437317.pkl-75.238.h5'\n",
    "model = tf.keras.models.load_model(f'{xom_data_path}plane_moon_model/{model_file}');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "predi = model[0].predict(x_predi_data).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importlib.reload(utils);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.log_predi_infor(x_full_predi_data, predi, f'{main_path}predi_logs/', model_file, datas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cutof = 0.98"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_preci_recal(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_roc(predi, y_predi_data, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_tpr_fpr(x_full_predi_data, predi, .5, 'moon_radiu', 30, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_confu_matri(x_full_predi_data, predi, cutof)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [130, 230], 'true',\n",
    "                       ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forma = \\\n",
    "'''\n",
    "utils.show_predi_compa(x_full_predi_data, predi, cutof, [30,130], 'true', ['plane_radiu', 'moon_radiu', 'plane_cut_injec'])\n",
    "'''\n",
    "forma_done = FormatCode(forma, style_config='PEP8')\n",
    "print(forma_done[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "t1",
   "language": "python",
   "name": "t1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
